Traceback (most recent call last):
  File "c:/Users/aylin/Documents/MechInt/transformer-addition-length-generalization/transformers.py", line 610, in <module>
    Trainer(config = config)
  File "c:/Users/aylin/Documents/MechInt/transformer-addition-length-generalization/transformers.py", line 469, in __init__
    self.model.to(config.device)
  File "C:\Users\aylin\anaconda3\envs\transformer-addition-length-generalization\lib\site-packages\torch\nn\modules\module.py", line 1174, in to
    return self._apply(convert)
  File "C:\Users\aylin\anaconda3\envs\transformer-addition-length-generalization\lib\site-packages\torch\nn\modules\module.py", line 780, in _apply
    module._apply(fn)
  File "C:\Users\aylin\anaconda3\envs\transformer-addition-length-generalization\lib\site-packages\torch\nn\modules\module.py", line 805, in _apply
    param_applied = fn(param)
  File "C:\Users\aylin\anaconda3\envs\transformer-addition-length-generalization\lib\site-packages\torch\nn\modules\module.py", line 1160, in convert
    return t.to(
  File "C:\Users\aylin\anaconda3\envs\transformer-addition-length-generalization\lib\site-packages\torch\cuda\__init__.py", line 305, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled